{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3siRuQbVglgG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "\n",
        "# 1. Chargement du tokenizer et des modèles\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "model_general = BertForSequenceClassification.from_pretrained(\"path_to_general_model\")\n",
        "model_covid = BertForSequenceClassification.from_pretrained(\"path_to_covid_model\")\n",
        "\n",
        "model_general.eval()\n",
        "model_covid.eval()\n",
        "\n",
        "# 2. Chargement du jeu de données COVID\n",
        "df_test = pd.read_csv(\"covid_test_dataset.csv\")\n",
        "\n",
        "texts = df_test[\"text\"].tolist()\n",
        "labels = df_test[\"label\"].tolist()  # 0 ou 1\n",
        "\n",
        "# 3. Fonction utilitaire pour prédire avec un modèle donné\n",
        "def predict_with_model(model, text_list):\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for text in text_list:\n",
        "            encoding = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "            outputs = model(**encoding)\n",
        "            pred = torch.argmax(outputs.logits, dim=1).item()\n",
        "            predictions.append(pred)\n",
        "    return predictions\n",
        "\n",
        "# 4. Obtenir les prédictions de chaque modèle\n",
        "preds_general = predict_with_model(model_general, texts)\n",
        "preds_covid = predict_with_model(model_covid, texts)\n",
        "\n",
        "# 5. Calcul et affichage des performances\n",
        "# Accuracy\n",
        "acc_general = accuracy_score(labels, preds_general)\n",
        "acc_covid = accuracy_score(labels, preds_covid)\n",
        "\n",
        "# F1-score (macro ou weighted selon vos besoins)\n",
        "f1_general = f1_score(labels, preds_general, average=\"weighted\")\n",
        "f1_covid = f1_score(labels, preds_covid, average=\"weighted\")\n",
        "\n",
        "print(\"=== Performances du modèle Général ===\")\n",
        "print(f\"Accuracy : {acc_general:.4f}\")\n",
        "print(f\"F1-score : {f1_general:.4f}\")\n",
        "print(classification_report(labels, preds_general, digits=4))\n",
        "\n",
        "print(\"\\n=== Performances du modèle COVID ===\")\n",
        "print(f\"Accuracy : {acc_covid:.4f}\")\n",
        "print(f\"F1-score : {f1_covid:.4f}\")\n",
        "print(classification_report(labels, preds_covid, digits=4))\n"
      ]
    }
  ]
}