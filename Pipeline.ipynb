{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Pipeline pour la préparation des données en inférence"
      ],
      "metadata": {
        "id": "D17LDkeVYsEd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hImE-WaDYpjQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "\n",
        "# Charger le tokenizer commun\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Charger les modèles pré-entraînés pour le domaine général et pour le COVID\n",
        "# Remplacez \"path_to_general_model\" et \"path_to_covid_model\" par le chemin ou l'identifiant de vos modèles\n",
        "model_general = BertForSequenceClassification.from_pretrained(\"path_to_general_model\")\n",
        "model_covid = BertForSequenceClassification.from_pretrained(\"path_to_covid_model\")\n",
        "\n",
        "def predict_fake_news(text, domain=\"general\"):\n",
        "    \"\"\"\n",
        "    Prédit si un article est Fake ou Real en fonction du domaine spécifié par l'utilisateur.\n",
        "\n",
        "    Args:\n",
        "        text (str): Le texte de l'article.\n",
        "        domain (str): Le domaine souhaité (\"general\" ou \"covid\").\n",
        "\n",
        "    Returns:\n",
        "        tuple: Une chaîne indiquant \"Fake\" ou \"Real\", et le domaine utilisé.\n",
        "    \"\"\"\n",
        "    # Préparation du texte\n",
        "    encoding = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "\n",
        "    # Sélection du modèle en fonction du domaine choisi\n",
        "    if domain.lower() == \"covid\":\n",
        "        model_to_use = model_covid\n",
        "    else:\n",
        "        model_to_use = model_general\n",
        "\n",
        "    model_to_use.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model_to_use(**encoding)\n",
        "\n",
        "    # Prédiction : 1 pour Fake, 0 pour Real\n",
        "    prediction = torch.argmax(outputs.logits, dim=1).item()\n",
        "    result = \"Fake\" if prediction == 1 else \"Real\"\n",
        "\n",
        "    return result, domain\n",
        "\n",
        "# Exemple d'utilisation\n",
        "if __name__ == \"__main__\":\n",
        "    text_exemple = \"Les nouvelles récentes sur la pandémie COVID-19 indiquent une évolution surprenante de la situation.\"\n",
        "    result, chosen_domain = predict_fake_news(text_exemple, domain=\"covid\")\n",
        "    print(f\"Domaine sélectionné : {chosen_domain} | Prédiction : {result}\")\n"
      ]
    }
  ]
}